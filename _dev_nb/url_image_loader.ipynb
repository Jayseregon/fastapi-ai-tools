{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.services.loaders.web.web_image_loader import WebImageLoader\n",
    "from src.configs.env_config import config\n",
    "import json\n",
    "from pathlib import Path\n",
    "from src.services.utils import DocumentJsonToolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "login_url = \"https://support.setics-sttar.com/en/support/login\"\n",
    "protected_url = \"https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/en/topic/introduction\"\n",
    "base_url_stad = \"https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/en/\"\n",
    "base_url_stpl = \"https://docs.setics-sttar.com/planner-user-manual/2.3/en/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(\"_dev_nb/output_data/web_loader\")\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "urls_file = output_path / \"setics_stad_urls.json\"\n",
    "stad_img_json = output_path / \"setics_images_docs_raw.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/en/topic/topology',\n",
       " 'https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/fr/topic/endpoint-support-context-menu',\n",
       " 'https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/fr/topic/search-by-cost-effectiveness-using-actual-costs',\n",
       " 'https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/en/topic/naming-rules-syntax',\n",
       " 'https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/fr/topic/duct-assembly-datasheet',\n",
       " 'https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/en/topic/cable-system-commands',\n",
       " 'https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/fr/topic/splicing-plans-options',\n",
       " 'https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/fr/topic/start-network-optimization',\n",
       " 'https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/fr/topic/installing-a-workstation-license',\n",
       " 'https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/en/topic/network-transmission-tree']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = json.loads(urls_file.read_text(encoding=\"utf-8\"))[:10]\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = await WebImageLoader.create_protected_loader(\n",
    "    username=config.SETICS_USER,\n",
    "    password=config.SETICS_PWD,\n",
    "    login_url=login_url,\n",
    "    check_url=protected_url,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stad URLs...\n",
      "Found 525 URLs for stad\n",
      "Parsing images...\n",
      "Parsed 424 documents\n",
      "Saving documents to _dev_nb/output_data/web_loader/setics_stad_img_docs.json\n",
      "Loading stpl URLs...\n",
      "Found 960 URLs for stpl\n",
      "Parsing images...\n",
      "Parsed 761 documents\n",
      "Saving documents to _dev_nb/output_data/web_loader/setics_stpl_img_docs.json\n"
     ]
    }
   ],
   "source": [
    "for target in [\"stad\", \"stpl\"]:\n",
    "    print(f\"Loading {target} URLs...\")\n",
    "    urls = json.loads(\n",
    "        (output_path / f\"setics_{target}_urls.json\").read_text(encoding=\"utf-8\")\n",
    "    )\n",
    "\n",
    "    print(f\"Found {len(urls)} URLs for {target}\", \"Parsing images...\", sep=\"\\n\")\n",
    "\n",
    "    docs = await loader.download_and_parse_images(urls=urls)\n",
    "\n",
    "    print(f\"Parsed {len(docs)} documents\")\n",
    "\n",
    "    img_file = output_path / f\"setics_{target}_img_docs.json\"\n",
    "\n",
    "    print(f\"Saving documents to {img_file}\")\n",
    "    DocumentJsonToolkit.documents_to_json(documents=docs, filename=img_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# await loader.initialize()\n",
    "# await loader.authenticate(\n",
    "#     username=config.SETICS_USER,\n",
    "#     password=config.SETICS_PWD,\n",
    "#     login_url=login_url,\n",
    "#     check_url=protected_url,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_urls_by_page = await loader.extract_image_urls(urls=urls)\n",
    "# image_urls_by_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img1 = image_urls_by_page[:2]\n",
    "# documents = await loader.download_and_parse_images(image_refs=img1)\n",
    "\n",
    "# for doc in documents:\n",
    "#     print(doc.page_content)\n",
    "#     print(\"\\n\\n===\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents = await loader.download_and_parse_images(urls=urls)\n",
    "# len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, doc in enumerate(documents):\n",
    "#     print(f\"=== Document {i} - length: {len(doc.page_content)} ===\\n\\n\")\n",
    "#     print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_prompt_template = \"\"\"You are an advanced image analysis assistant tasked with extracting and describing visual content.\n",
    "\n",
    "# ## Part 1: Concise Summary\n",
    "# Provide a concise summary of the image optimized for retrieval (1-2 sentences).\n",
    "\n",
    "# ## Part 2: Visual Description\n",
    "# Describe the image in detail, including:\n",
    "# - Type of image (diagram, screenshot, photograph, chart, etc.)\n",
    "# - Key visual elements and their arrangement\n",
    "# - UI elements if this is a screenshot\n",
    "# - Any notable visual patterns or structures\n",
    "\n",
    "# ## Part 3: Text Content\n",
    "# Extract ALL text visible in the image, preserving:\n",
    "# - Headers and titles\n",
    "# - Menu items and navigation elements\n",
    "# - Labels and annotations\n",
    "# - Table contents\n",
    "# - Text in diagrams or charts\n",
    "# - Button text and UI elements\n",
    "# - Any other textual information\n",
    "\n",
    "# You MUST ensure that your final output is contained within 1800 characters. Output should be in markdown format, without explanatory text, without any unnecessary whitespace (no extra line breaks or indentations) and without markdown delimiter ``` at the beginning.\n",
    "# \"\"\"\n",
    "\n",
    "# custom_prompt = PromptTemplate.from_template(custom_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_prompt_template = \"\"\"You are an advanced image analysis assistant tasked with extracting and describing visual content for a retrieval-augmented generation system.\n",
    "\n",
    "# ## Part 1: Concise Summary (50-75 words)\n",
    "# Provide a concise summary that captures the image's core purpose and content. Focus on what the image represents functionally rather than just visually.\n",
    "\n",
    "# ## Part 2: Visual Description (100-150 words)\n",
    "# Describe the image with these key aspects:\n",
    "# - Type of image (screenshot, diagram, chart, photo, etc.)\n",
    "# - Main subject and its purpose or function\n",
    "# - Key visual elements and their relationships\n",
    "# - For screenshots: interface purpose, main controls, and data being displayed\n",
    "# - For diagrams/charts: what information is being conveyed and how\n",
    "\n",
    "# ## Part 3: Text Content (remaining space)\n",
    "# Extract ALL visible text in the image, prioritizing by importance:\n",
    "# 1. Headers, titles and key labels\n",
    "# 2. Navigation elements and structural information\n",
    "# 3. Table headers and important cell data\n",
    "# 4. Button text and interactive elements\n",
    "# 5. Supporting text and annotations\n",
    "\n",
    "# IMPORTANT:\n",
    "# - Ensure high semantic density by focusing on meaningful content\n",
    "# - Avoid redundancy between sections\n",
    "# - Organize text content logically by visual hierarchy\n",
    "# - Include semantic markers for context (e.g., \"Button:\", \"Menu:\", \"Header:\")\n",
    "# - Prioritize completeness of text extraction over visual description if space is limited\n",
    "\n",
    "# Format output as compact markdown with minimal formatting, without explanatory text, and without markdown delimiter ``` at the beginning.\n",
    "# Total output must be under 1800 characters.\n",
    "# \"\"\"\n",
    "\n",
    "# custom_prompt = PromptTemplate.from_template(custom_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_prompt_template = \"\"\"You are an advanced image analysis assistant tasked with extracting and describing visual content for a retrieval-augmented generation system.\n",
    "\n",
    "# ## Part 1: Concise Summary (50-75 words)\n",
    "# Provide a concise summary that captures the image's core purpose and content. Focus on what the image represents functionally rather than just visually.\n",
    "\n",
    "# ## Part 2: Visual Description (100-150 words)\n",
    "# Describe the image with these key aspects:\n",
    "# - Type of image (screenshot, diagram, chart, photo, etc.)\n",
    "# - Main subject and its purpose or function\n",
    "# - Key visual elements and their relationships\n",
    "# - For screenshots: interface purpose, main controls, and data being displayed\n",
    "# - For diagrams/charts: what information is being conveyed and how\n",
    "\n",
    "# ## Part 3: Text Content (remaining space)\n",
    "# Extract ALL visible text in the image, prioritizing by importance:\n",
    "# 1. Headers, titles and key labels\n",
    "# 2. Navigation elements and structural information\n",
    "# 3. Table headers and important cell data\n",
    "# 4. Button text and interactive elements\n",
    "# 5. Supporting text and annotations\n",
    "\n",
    "# IMPORTANT FORMATTING INSTRUCTIONS:\n",
    "# - Use proper markdown tables for any tabular data (with | and - formatting)\n",
    "# - Ensure high semantic density by focusing on meaningful content\n",
    "# - Avoid redundancy between sections\n",
    "# - Organize text content logically by visual hierarchy\n",
    "# - Include semantic markers for context (e.g., \"Button:\", \"Menu:\", \"Header:\")\n",
    "# - Prioritize completeness of text extraction over visual description if space is limited\n",
    "\n",
    "# Format output as compact markdown with minimal formatting, without explanatory text, and without markdown delimiter ``` at the beginning.\n",
    "# Total output must be under 1800 characters.\n",
    "# \"\"\"\n",
    "\n",
    "# custom_prompt = PromptTemplate.from_template(custom_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_prompt_template = \"\"\"You are an advanced image analysis assistant tasked with extracting and describing visual content for a retrieval-augmented generation system.\n",
    "\n",
    "# ## Part 1: Concise Summary (50-75 words)\n",
    "# Provide a concise summary that captures the image's core purpose and content. Focus on what the image represents functionally rather than just visually.\n",
    "\n",
    "# ## Part 2: Visual Description (100-150 words)\n",
    "# Describe the image with these key aspects:\n",
    "# - Type of image (screenshot, diagram, chart, photo, etc.)\n",
    "# - Main subject and its purpose or function\n",
    "# - Key visual elements and their relationships\n",
    "# - For screenshots: interface purpose and main controls\n",
    "# - For diagrams/charts: what information is being conveyed and how\n",
    "\n",
    "# ## Part 3: Text Content (remaining space)\n",
    "# Extract ALL visible text in the image, prioritizing by importance:\n",
    "# 1. Headers, titles and key labels\n",
    "# 2. Table data (using proper markdown tables)\n",
    "# 3. Critical UI elements and buttons\n",
    "# 4. Supporting text and annotations\n",
    "\n",
    "# IMPORTANT FORMATTING INSTRUCTIONS:\n",
    "# - Use proper markdown tables for tabular data (with | and - formatting)\n",
    "# - If needed, abbreviate long table headers to save space\n",
    "# - For large tables, prioritize headers and most important rows\n",
    "# - Include semantic markers for non-table elements (e.g., \"Button:\", \"Header:\")\n",
    "# - Be extremely concise in all sections while preserving critical information\n",
    "\n",
    "# Format output as compact markdown with minimal formatting.\n",
    "# Output must be without explanatory text, and without markdown delimiter ``` at the beginning.\n",
    "# Total output must be under 2500 characters.\n",
    "# \"\"\"\n",
    "\n",
    "# custom_prompt = PromptTemplate.from_template(custom_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_prompt_template = \"\"\"You are an advanced image analysis assistant tasked with extracting and describing visual content for a retrieval-augmented generation system.\n",
    "\n",
    "# ## Part 1: Concise Summary (50-75 words)\n",
    "# Provide a concise summary that captures the image's core purpose and content. Focus on what the image represents functionally rather than just visually. Identify the primary information being conveyed.\n",
    "\n",
    "# ## Part 2: Visual Description (100-150 words)\n",
    "# Describe the image with these key aspects:\n",
    "# - Type of image (screenshot, diagram, chart, photo, etc.) or combination if mixed format\n",
    "# - Main subject and its purpose or function\n",
    "# - Key visual elements, their relationships, and hierarchical organization\n",
    "# - For screenshots: interface purpose and main controls\n",
    "# - For diagrams/charts: what information is being conveyed and key relationships\n",
    "# - For flowcharts/processes: sequence, decision points, and connections between elements\n",
    "\n",
    "# ## Part 3: Text Content (remaining space)\n",
    "# Extract ALL visible text in the image, prioritizing by importance:\n",
    "# 1. Headers, titles and key labels\n",
    "# 2. Table data (using proper markdown tables)\n",
    "# 3. Critical UI elements and buttons\n",
    "# 4. Supporting text and annotations\n",
    "\n",
    "# IMPORTANT FORMATTING INSTRUCTIONS:\n",
    "# - Use proper markdown tables for tabular data (with | and - formatting)\n",
    "# - For complex or multiple tables, include a brief label before each table\n",
    "# - If needed, abbreviate long table headers to save space\n",
    "# - For large tables, prioritize headers and most important rows\n",
    "# - Include semantic markers for non-table elements (e.g., \"Button:\", \"Header:\")\n",
    "# - For diagrams with connected elements, indicate relationships with \"â†’\" or similar notation\n",
    "# - If text is unclear or possibly inaccurate due to image quality, indicate with [?]\n",
    "# - For mathematical equations or special notation, use markdown's math formatting\n",
    "# - Be extremely concise in all sections while preserving critical information\n",
    "\n",
    "# Format output as compact markdown with minimal formatting.\n",
    "# Output must be without explanatory text, and without markdown delimiter ``` at the beginning.\n",
    "# Total output must be under 2500 characters.\n",
    "# \"\"\"\n",
    "\n",
    "# custom_prompt = PromptTemplate.from_template(custom_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# async def download_and_parse_image(image_ref: Dict[str, str]) -> Document:\n",
    "#     image_url = image_ref[\"url\"]\n",
    "#     llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=config.OPENAI_API_KEY)\n",
    "#     parser = LLMImageBlobParser(model=llm, prompt=custom_prompt)\n",
    "#     try:\n",
    "#         async with aiohttp.ClientSession() as session:\n",
    "#             async with session.get(image_url) as response:\n",
    "#                 if response.status != 200:\n",
    "#                     print(f\"Failed to download image: {response.status}\")\n",
    "#                     return None\n",
    "\n",
    "#                 # Get binary data\n",
    "#                 image_data = await response.read()\n",
    "\n",
    "#                 # Create blob object\n",
    "#                 blob = Blob(data=image_data, metadata=image_ref)\n",
    "\n",
    "#                 # Parse with LLMImageBlobParser\n",
    "#                 documents = parser.parse(blob=blob)[0]\n",
    "\n",
    "#                 return documents\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing image: {str(e)}\")\n",
    "#         return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img1 = image_urls_by_page[0]\n",
    "# document = await download_and_parse_image(image_ref=img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(document.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(document.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
