{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.configs.env_config import config\n",
    "from src.services.db import chroma_service\n",
    "from pathlib import Path\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import FlashrankRerank\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from pprint import pprint\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from src.services.utils import (\n",
    "    text_splitter_recursive_char,\n",
    "    create_chunk_ids,\n",
    "    json_to_documents,\n",
    ")\n",
    "from src.services.processors import DocumentsPreprocessing\n",
    "from src.services.vectorstore import ChromaStore\n",
    "from src.services.retrievers import MultiQRerankedRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1744037033256746210"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = chroma_service()\n",
    "client.heartbeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"local_collection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if client.get_collection(collection_name):\n",
    "    client.delete_collection(collection_name)\n",
    "\n",
    "collection = client.get_or_create_collection(collection_name)\n",
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_data_src = Path(\"_dev_nb/output_data/pdf_loader\")\n",
    "web_data_src = Path(\"_dev_nb/output_data/web_loader\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 525 documents\n"
     ]
    }
   ],
   "source": [
    "json_path = web_data_src / \"setics_stad_docs_clean.json\"\n",
    "docs = json_to_documents(filename=json_path)\n",
    "\n",
    "print(f\"Got {len(docs)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 1145 chunks\n"
     ]
    }
   ],
   "source": [
    "processor = DocumentsPreprocessing()\n",
    "chunks, ids = await processor(documents=docs)\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = ChromaStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1145"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll = client.get_collection(collection_name)\n",
    "coll.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.get(where={\"$exists\": \"source\"}, include=[\"metadatas\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['topology-0-c5a70271',\n",
       "  'topology-1-2acf1e65',\n",
       "  'topology-2-1cf93343',\n",
       "  'topology-3-d267b2c6',\n",
       "  'endpoint-support-context-menu-4-1aca362e'],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [{'title': 'Topology - Setics Sttar Advanced Designer  |  User Manual - Version 2.3',\n",
       "   'description': 'The Topology tab allows you to specify how Setics Sttar Advanced Designer should interpret and model the support entities: Infrastructure tab - support...',\n",
       "   'source': 'https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/en/topic/topology',\n",
       "   'id': 'topology-0-c5a70271',\n",
       "   'language': 'en'},\n",
       "  {'title': 'Topology - Setics Sttar Advanced Designer  |  User Manual - Version 2.3',\n",
       "   'language': 'en',\n",
       "   'id': 'topology-1-2acf1e65',\n",
       "   'source': 'https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/en/topic/topology',\n",
       "   'description': 'The Topology tab allows you to specify how Setics Sttar Advanced Designer should interpret and model the support entities: Infrastructure tab - support...'},\n",
       "  {'id': 'topology-2-1cf93343',\n",
       "   'title': 'Topology - Setics Sttar Advanced Designer  |  User Manual - Version 2.3',\n",
       "   'source': 'https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/en/topic/topology',\n",
       "   'description': 'The Topology tab allows you to specify how Setics Sttar Advanced Designer should interpret and model the support entities: Infrastructure tab - support...',\n",
       "   'language': 'en'},\n",
       "  {'language': 'en',\n",
       "   'id': 'topology-3-d267b2c6',\n",
       "   'description': 'The Topology tab allows you to specify how Setics Sttar Advanced Designer should interpret and model the support entities: Infrastructure tab - support...',\n",
       "   'title': 'Topology - Setics Sttar Advanced Designer  |  User Manual - Version 2.3',\n",
       "   'source': 'https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/en/topic/topology'},\n",
       "  {'description': 'Menu contextuel de l’onglet Architecture Passive pour les sites Commande ou paramètre Description Disposition La disposition permet de mettre un support de...',\n",
       "   'language': 'fr',\n",
       "   'source': 'https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/fr/topic/endpoint-support-context-menu',\n",
       "   'id': 'endpoint-support-context-menu-4-1aca362e',\n",
       "   'title': 'Menu contextuel des sites - Setics Sttar Advanced Designer  |  User Manual - Version 2.3'}],\n",
       " 'documents': ['#### 5.5.4.4. Topology\\n\\nThe Topology tab allows you to specify how Setics Sttar Advanced Designer should interpret and model the support entities:\\nInfrastructure tab - support properties - topology tab\\n\\nCommand or setting\\nDescription\\n\\n Allow section geometries to be modified\\n Specifies what happens when discontinuities are ignored according to the Resolution setting in the Import Infrastructure Data screen. When set, the geometry will be modified to extend the line and make the connection. When not set, the geometries will not be connected, but Setics Sttar Advanced Designer algorithms will still consider them to be connected.\\n\\n Name\\n Name of the interconnection between the different nodes and the different infrastructures.\\nBy default, the name will be of the form “Support 1 <-> Support 2”. It can be changed later.\\nSelecting the box on the left allows you to add the interconnection in the calculations of Setics Sttar Advanced Designer .',\n",
       "  'Connects to\\n Choice of the type of connected infrastructure.\\n\\n Cable Affinity\\n Choice of the interconnection behaviour according to the chosen infrastructure. The behaviour can be: “Indifferent”, “Standalone” or a type of infrastructure present in the current project.\\nThe purpose of this setting is to simplify the configuration of algorithms (cabling, etc.) by ensuring that an interconnection or distribution infrastructure behaves like any of the infrastructures it connects. By default, this setting is set to “Indifferent” for the interconnections of infrastructures that can be moved between them and points to a reusable pathway support to which a node or an endpoint is potentially attached in the case of a distribution.\\nFinally, if you want to specify specific algorithm settings for these interconnections, you must choose the value “Standalone”. Then, in the cabling settings screen, you can choose the interconnection support concerned (see details in Cable System Tab).',\n",
       "  'Duct Affinity\\n Choice of the interconnection behaviour according to the chosen infrastructure. The behaviour can be: “Indifferent”, “Standalone” or a type of infrastructure present in the current project.\\nThe purpose of this setting is to simplify the configuration of algorithms (cabling, etc.) by ensuring that an interconnection or distribution infrastructure behaves like any of the infrastructures it connects. By default, this setting is set to “Indifferent” for the interconnections of infrastructures that can be moved between them and points to a reusable pathway support to which a node or an endpoint is potentially attached in the case of a distribution.\\nFinally, if you want to specify specific algorithm settings for these interconnections, you must choose the value “Standalone”. Then, in the cabling settings screen, you can choose the interconnection support concerned (see details in Ducts Tab).',\n",
       "  'Fixed Cost per Conn. (€)\\n Fixed cost for interconnecting the two infrastructures, the creation of a room for example (in €).\\n\\n Linear Cost (€/m)\\n Linear cost of the section to be added to connect the two infrastructures (in m/€).\\n\\n Max. Conn. Distance. (m)\\n Maximum distance authorizing a connection between the two supports (in m).\\nThe software will create the interconnection section for connecting two nearby infrastructure ends. The distance is estimated using line of sight.\\n\\n*For the routing algorithm and the other algorithms to work properly, we recommend to avoid using zero costs.',\n",
       "  '#### 5.6.3.2. Menu contextuel des sites\\n\\nMenu contextuel de l’onglet Architecture Passive pour les sites\\n\\nCommande ou paramètre\\nDescription\\n\\nDisposition\\n La disposition permet de mettre un support de nœud ou de site en avant ou en arrière.\\n\\nMarquer réseau de transport\\n Marque le nœud comme étant un réseau de transport.\\n\\nImporter des données…\\n Ajout d’une couche SIG de site.\\nVoir détails au point Importer des sites.\\n\\nRecharger des données\\n Recharge la couche SIG sélectionnée.\\n\\nSupprimer le support\\n Supprime la couche SIG d’architecture sélectionnée.\\n\\nPropriété…\\n Ouverture de la fenêtre de définitions des propriétés des sites.\\nVoir détails au point Propriétés des sites.'],\n",
       " 'data': None,\n",
       " 'uris': None,\n",
       " 'included': [<IncludeEnum.metadatas: 'metadatas'>,\n",
       "  <IncludeEnum.documents: 'documents'>]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll.get(limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources = await store._get_source_tracker(collection_name=collection_name)\n",
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = await store.add_documents(\n",
    "    documents=chunks, ids=ids, collection_name=collection_name\n",
    ")\n",
    "\n",
    "print(f\"Added {count} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_collection(collection_name).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "added_count, docs_replaced, sources_updated = await store.replace_documents(\n",
    "    documents=chunks, ids=ids, collection_name=collection_name\n",
    ")\n",
    "\n",
    "print(f\"Added {added_count} documents\")\n",
    "print(f\"Replaced {docs_replaced} documents\")\n",
    "print(f\"Updated {sources_updated} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_collection(collection_name).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the purpose of the Advanced Designer?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = MultiQRerankedRetriever()\n",
    "results = await retriever(query=query, collection_name=collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    pprint(f\"Metadata: {result.metadata}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prototyping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    api_key=config.OPENAI_API_KEY,\n",
    "    max_tokens=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_json_path = pdf_data_src / \"xplore_pdf_3_clean.json\"\n",
    "pdf_docs = json_to_documents(filename=pdf_json_path)\n",
    "len(pdf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_json_path = web_data_src / \"setics_stad_docs_clean.json\"\n",
    "web_docs = json_to_documents(filename=web_json_path)\n",
    "len(web_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_json_path_2 = web_data_src / \"setics_stpl_docs_clean.json\"\n",
    "web_docs_2 = json_to_documents(filename=web_json_path_2)\n",
    "len(web_docs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_json_path = web_data_src / \"setics_stad_img_docs.json\"\n",
    "img_docs = json_to_documents(filename=img_json_path)\n",
    "len(img_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, doc in enumerate(pdf_docs):\n",
    "#     print(f\"Doc {i}: length {len(doc.page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_chunks = text_splitter_recursive_char(pdf_docs)\n",
    "len(pdf_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, doc in enumerate(web_docs):\n",
    "#     print(f\"Doc {i}: length {len(doc.page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_chunks = text_splitter_recursive_char(web_docs)\n",
    "len(web_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_chunks_2 = text_splitter_recursive_char(web_docs_2)\n",
    "len(web_chunks_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, doc in enumerate(web_chunks):\n",
    "#     print(f\"Doc {i}: length {len(doc.page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_chunks_ids = create_chunk_ids(pdf_chunks)\n",
    "web_chunks_ids = create_chunk_ids(web_chunks)\n",
    "web_chunks_2_ids = create_chunk_ids(web_chunks_2)\n",
    "\n",
    "img_ids = [i.metadata[\"id\"] for i in img_docs]\n",
    "\n",
    "print(\n",
    "    pdf_chunks_ids[:2], web_chunks_ids[:2], web_chunks_2_ids[:2], img_ids[:2], sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(web_chunks[10].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_embedding = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\", openai_api_key=config.OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma(\n",
    "    client=client,\n",
    "    collection_name=collection.name,\n",
    "    embedding_function=openai_embedding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_with_ids = [\n",
    "    (web_chunks, web_chunks_ids),\n",
    "    (pdf_chunks, pdf_chunks_ids),\n",
    "    (web_chunks_2, web_chunks_2_ids),\n",
    "    (img_docs, img_ids),\n",
    "]\n",
    "\n",
    "for docs, ids in documents_with_ids:\n",
    "    vector_store.add_documents(documents=docs, ids=ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever = vector_store.as_retriever(\n",
    "#     search_type=\"mmr\",\n",
    "#     # search_type=\"similarity_score_threshold\",\n",
    "#     # search_kwargs={\"k\": 3, \"score_threshold\": 0.5},\n",
    "#     search_kwargs={\"k\": 3},\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever = MultiQueryRetriever.from_llm(retriever=vector_store.as_retriever(), llm=llm)\n",
    "\n",
    "# retriever = SelfQueryRetriever.from_llm(\n",
    "#     llm=llm,\n",
    "#     vectorstore=vector_store,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapping base retriever with FlashRank compressor\n",
    "\n",
    "# create MultiQueryRetriever\n",
    "base_retriever = vector_store.as_retriever(search_kwargs={\"k\": 10})\n",
    "multi_query_retriever = MultiQueryRetriever.from_llm(retriever=base_retriever, llm=llm)\n",
    "\n",
    "# add reranker on top\n",
    "compressor = FlashrankRerank(top_n=3)\n",
    "retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=multi_query_retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"What is the installation requirement for flower pot?\"\n",
    "# query = \"What can you tell me about Setics Sttar?\"\n",
    "# query = \"In Sttar, how to add a new infrastructure layer?\"\n",
    "# query = \"In Sttar, how to manually split some lines in the interface, in the map view?\"\n",
    "# query = \" In sttar, how can we manage the support properties, for the reusable infrastructure?\"\n",
    "query = \" What is the differences between the advanced designer and the planner?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set logging for the queries\n",
    "# import logging\n",
    "\n",
    "# logging.basicConfig()\n",
    "# logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = retriever.invoke(query)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for result in results:\n",
    "#     print(result.page_content)\n",
    "#     print(\"\\n\\n===\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chatbot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    api_key=config.OPENAI_API_KEY,\n",
    "    # max_tokens=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "docs_content = \"\\n\\n\".join(doc.page_content for doc in results)\n",
    "\n",
    "messages = prompt.invoke({\"question\": query, \"context\": docs_content})\n",
    "response = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.get(\n",
    "    ids=results[0].metadata[\"id\"], include=[\"documents\", \"metadatas\", \"embeddings\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
