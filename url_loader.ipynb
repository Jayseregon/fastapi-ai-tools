{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.services.utils import setics_web_loader_service\n",
    "from src.services.utils import public_web_loader_service\n",
    "from src.services.utils.seticsWebLoaderService import SeticsWebLoaderService\n",
    "from src.services.utils.publicWebLoader import PublicWebLoaderService\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"jeremie.bitsch@telecon.ca\"\n",
    "password = \"sujnux-6fadfu-ryJnok\"\n",
    "\n",
    "\n",
    "login_url = \"https://support.setics-sttar.com/en/support/login\"\n",
    "protected_url = \"https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/en/topic/introduction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# login_url = \"https://support.setics-sttar.com/en/support/login\"\n",
    "# protected_url = \"https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/en/topic/introduction\"\n",
    "\n",
    "# # Start a session\n",
    "# session = requests.Session()\n",
    "\n",
    "# # First get the login page to collect any necessary tokens\n",
    "# login_page = session.get(login_url)\n",
    "# soup = BeautifulSoup(login_page.content, \"html.parser\")\n",
    "\n",
    "# # Extract authenticity token (CSRF protection)\n",
    "# authenticity_token = None\n",
    "# token_input = soup.find(\"input\", attrs={\"name\": \"authenticity_token\"})\n",
    "# if token_input:\n",
    "#     authenticity_token = token_input.get(\"value\")\n",
    "#     print(f\"Found authenticity token: {authenticity_token}\")\n",
    "\n",
    "# # Prepare login payload\n",
    "# payload = {}\n",
    "# if authenticity_token:\n",
    "#     payload[\"authenticity_token\"] = authenticity_token\n",
    "\n",
    "# # Add login credentials - adjust field names if needed based on the form\n",
    "# payload[\"user[email]\"] = username\n",
    "# payload[\"user[password]\"] = password\n",
    "\n",
    "# # Set browser-like headers\n",
    "# headers = {\n",
    "#     \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.3 Safari/605.1.15\",\n",
    "#     \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "#     \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "#     \"Origin\": \"https://support.setics-sttar.com\",\n",
    "#     \"Referer\": login_url,\n",
    "# }\n",
    "\n",
    "# # Submit login\n",
    "# login_response = session.post(\n",
    "#     login_url, data=payload, headers=headers, allow_redirects=True\n",
    "# )\n",
    "# print(\n",
    "#     f\"Login status: {login_response.status_code}, URL after login: {login_response.url}\"\n",
    "# )\n",
    "\n",
    "# # Check login success by verifying cookies\n",
    "# print(f\"Cookies after login: {list(session.cookies.keys())}\")\n",
    "\n",
    "# # Try accessing the protected URL directly first to verify access\n",
    "# test_access = session.get(protected_url, headers=headers)\n",
    "# print(f\"Protected page access status: {test_access.status_code}\")\n",
    "\n",
    "\n",
    "# # Configure the WebBaseLoader correctly\n",
    "# loader = WebBaseLoader(\n",
    "#     web_paths=[protected_url],\n",
    "#     requests_kwargs={\"headers\": headers},  # Note the 's' in requests_kwargs\n",
    "#     session=session,  # Pass session directly in constructor\n",
    "# )\n",
    "\n",
    "# try:\n",
    "#     docs = loader.load()\n",
    "#     print(f\"Successfully loaded {len(docs)} documents\")\n",
    "#     for doc in docs:\n",
    "#         # Print just the beginning to verify content\n",
    "#         print(doc.page_content[:300] + \"...\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error loading documents: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# login_url = \"https://support.setics-sttar.com/en/support/login\"\n",
    "# protected_url = \"https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/en/topic/introduction\"\n",
    "\n",
    "# # Start a session\n",
    "# session = requests.Session()\n",
    "\n",
    "# # First get the login page to collect any necessary tokens\n",
    "# login_page = session.get(login_url)\n",
    "# soup = BeautifulSoup(login_page.content, \"html.parser\")\n",
    "\n",
    "# # Extract authenticity token (CSRF protection)\n",
    "# authenticity_token = None\n",
    "# token_input = soup.find(\"input\", attrs={\"name\": \"authenticity_token\"})\n",
    "# if token_input:\n",
    "#     authenticity_token = token_input.get(\"value\")\n",
    "#     print(f\"Found authenticity token: {authenticity_token}\")\n",
    "\n",
    "# # Prepare login payload\n",
    "# payload = {}\n",
    "# if authenticity_token:\n",
    "#     payload[\"authenticity_token\"] = authenticity_token\n",
    "\n",
    "# # Add login credentials - adjust field names if needed based on the form\n",
    "# payload[\"user[email]\"] = username\n",
    "# payload[\"user[password]\"] = password\n",
    "\n",
    "# # Set browser-like headers\n",
    "# headers = {\n",
    "#     \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.3 Safari/605.1.15\",\n",
    "#     \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "#     \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "#     \"Origin\": \"https://support.setics-sttar.com\",\n",
    "#     \"Referer\": login_url,\n",
    "# }\n",
    "\n",
    "# # Submit login\n",
    "# login_response = session.post(\n",
    "#     login_url, data=payload, headers=headers, allow_redirects=True\n",
    "# )\n",
    "# print(\n",
    "#     f\"Login status: {login_response.status_code}, URL after login: {login_response.url}\"\n",
    "# )\n",
    "\n",
    "# # Check login success by verifying cookies\n",
    "# print(f\"Cookies after login: {list(session.cookies.keys())}\")\n",
    "\n",
    "# # Try accessing the protected URL directly first to verify access\n",
    "# test_access = session.get(protected_url, headers=headers)\n",
    "# print(f\"Protected page access status: {test_access.status_code}\")\n",
    "\n",
    "\n",
    "# # After successful login, create custom extractor functions that use your authenticated session\n",
    "# def content_extractor(html: str) -> str:\n",
    "#     \"\"\"Extract clean text from HTML content.\"\"\"\n",
    "#     soup = BeautifulSoup(html, \"html.parser\")\n",
    "#     # Remove script and style elements\n",
    "#     for script in soup([\"script\", \"style\"]):\n",
    "#         script.extract()\n",
    "#     text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "#     # Clean up text by removing excessive newlines\n",
    "#     text = re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", text)\n",
    "#     return text\n",
    "\n",
    "\n",
    "# def session_fetch_url(url: str) -> Optional[str]:\n",
    "#     \"\"\"Custom function to fetch URLs using our authenticated session\"\"\"\n",
    "#     try:\n",
    "#         response = session.get(url, headers=headers)\n",
    "#         if response.status_code == 200:\n",
    "#             return response.text\n",
    "#         else:\n",
    "#             print(f\"Failed to fetch {url}: Status {response.status_code}\")\n",
    "#             return None\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error fetching {url}: {e}\")\n",
    "#         return None\n",
    "\n",
    "\n",
    "# # Extract the base URL from the protected_url\n",
    "\n",
    "# parsed_url = urlparse(protected_url)\n",
    "# print(f\"Parsed URL: {parsed_url}\")\n",
    "\n",
    "# base_url = f\"{parsed_url.scheme}://{parsed_url.netloc}\"\n",
    "# print(f\"Base URL: {base_url}\")\n",
    "\n",
    "\n",
    "# # Create a custom wrapper for RecursiveUrlLoader that uses our session\n",
    "# class AuthenticatedRecursiveUrlLoader:\n",
    "#     def __init__(self, url, session, headers, **kwargs):\n",
    "#         self.url = url\n",
    "#         self.session = session\n",
    "#         self.headers = headers\n",
    "#         self.kwargs = kwargs\n",
    "#         # Initialize the actual loader\n",
    "#         self.loader = RecursiveUrlLoader(url, **kwargs)\n",
    "\n",
    "#     def load(self):\n",
    "#         # Get all URLs first using the loader's discovery mechanism\n",
    "#         all_urls = []\n",
    "#         try:\n",
    "#             # This will crawl for links but we don't use the content yet\n",
    "#             placeholder_docs = self.loader.load()\n",
    "#             all_urls = [doc.metadata[\"source\"] for doc in placeholder_docs]\n",
    "#             print(f\"Found {len(all_urls)} URLs to fetch\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error discovering URLs: {e}\")\n",
    "\n",
    "#         # Now use our authenticated session to fetch each URL\n",
    "#         docs = []\n",
    "#         for url in all_urls:\n",
    "#             html = session_fetch_url(url)\n",
    "#             if html:\n",
    "#                 from langchain_core.documents import Document\n",
    "\n",
    "#                 text = content_extractor(html)\n",
    "#                 docs.append(Document(page_content=text, metadata={\"source\": url}))\n",
    "\n",
    "#         return docs\n",
    "\n",
    "\n",
    "# # Now use the custom loader\n",
    "# custom_loader = AuthenticatedRecursiveUrlLoader(\n",
    "#     url=base_url,  # Start from the base URL\n",
    "#     session=session,\n",
    "#     headers=headers,\n",
    "#     max_depth=3,  # Control crawling depth\n",
    "#     prevent_outside=True,\n",
    "#     exclude_dirs=[],  # Add any directories you want to exclude\n",
    "#     extractor=content_extractor,\n",
    "# )\n",
    "\n",
    "# try:\n",
    "#     docs = custom_loader.load()\n",
    "#     print(f\"Successfully loaded {len(docs)} documents\")\n",
    "#     # Print the titles/URLs of what was found\n",
    "#     for i, doc in enumerate(docs[:5]):  # Show first 5\n",
    "#         print(f\"{i + 1}. {doc.metadata['source']}\")\n",
    "#         print(f\"Content preview: {doc.page_content[:100]}...\\n\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error loading documents: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class UrlDiscoverer:\n",
    "#     def __init__(self, session, headers=None):\n",
    "#         \"\"\"Initialize with an authenticated session.\"\"\"\n",
    "#         self.session = session\n",
    "#         self.headers = headers or {}\n",
    "#         self.visited_urls = set()\n",
    "\n",
    "#     def discover_urls(\n",
    "#         self, base_url: str, max_depth: int = 2, same_domain_only: bool = True\n",
    "#     ) -> List[str]:\n",
    "#         \"\"\"\n",
    "#         Discover all URLs reachable from the base URL up to max_depth.\n",
    "\n",
    "#         Args:\n",
    "#             base_url: Starting URL (must be accessible with your authenticated session)\n",
    "#             max_depth: Maximum depth to crawl (default: 2)\n",
    "#             same_domain_only: Only include URLs from the same domain (default: True)\n",
    "\n",
    "#         Returns:\n",
    "#             List of discovered URLs\n",
    "#         \"\"\"\n",
    "#         base_domain = urlparse(base_url).netloc\n",
    "#         to_crawl = [(base_url, 0)]  # (url, depth)\n",
    "#         discovered_urls = set()\n",
    "\n",
    "#         while to_crawl:\n",
    "#             url, depth = to_crawl.pop(0)\n",
    "\n",
    "#             # Skip if already visited or beyond max depth\n",
    "#             if url in self.visited_urls or depth > max_depth:\n",
    "#                 continue\n",
    "\n",
    "#             self.visited_urls.add(url)\n",
    "#             print(f\"Fetching: {url} (depth {depth})\")\n",
    "\n",
    "#             try:\n",
    "#                 # Use the authenticated session\n",
    "#                 response = self.session.get(url, headers=self.headers)\n",
    "#                 if response.status_code != 200:\n",
    "#                     print(f\"Failed to fetch {url}: Status {response.status_code}\")\n",
    "#                     continue\n",
    "\n",
    "#                 # Add to discovered URLs\n",
    "#                 discovered_urls.add(url)\n",
    "\n",
    "#                 # Don't crawl deeper if at max depth\n",
    "#                 if depth == max_depth:\n",
    "#                     continue\n",
    "\n",
    "#                 # Find all links\n",
    "#                 soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "#                 for link in soup.find_all(\"a\", href=True):\n",
    "#                     href = link[\"href\"]\n",
    "#                     full_url = urljoin(url, href)\n",
    "\n",
    "#                     # Filter URLs\n",
    "#                     if same_domain_only and urlparse(full_url).netloc != base_domain:\n",
    "#                         continue\n",
    "\n",
    "#                     # Filter out fragments and non-http(s) URLs\n",
    "#                     if not full_url.startswith((\"http://\", \"https://\")):\n",
    "#                         continue\n",
    "\n",
    "#                     # Skip URLs already visited or queued\n",
    "#                     if full_url in self.visited_urls or any(\n",
    "#                         full_url == u for u, _ in to_crawl\n",
    "#                     ):\n",
    "#                         continue\n",
    "\n",
    "#                     # Add to crawl queue\n",
    "#                     to_crawl.append((full_url, depth + 1))\n",
    "\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error fetching {url}: {e}\")\n",
    "\n",
    "#         return list(discovered_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# login_url = \"https://support.setics-sttar.com/en/support/login\"\n",
    "# protected_url = \"https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/en/topic/introduction\"\n",
    "\n",
    "# # Start a session\n",
    "# session = requests.Session()\n",
    "\n",
    "# # First get the login page to collect any necessary tokens\n",
    "# login_page = session.get(login_url)\n",
    "# soup = BeautifulSoup(login_page.content, \"html.parser\")\n",
    "\n",
    "# # Extract authenticity token (CSRF protection)\n",
    "# authenticity_token = None\n",
    "# token_input = soup.find(\"input\", attrs={\"name\": \"authenticity_token\"})\n",
    "# if token_input:\n",
    "#     authenticity_token = token_input.get(\"value\")\n",
    "#     print(f\"Found authenticity token: {authenticity_token}\")\n",
    "\n",
    "# # Prepare login payload\n",
    "# payload = {}\n",
    "# if authenticity_token:\n",
    "#     payload[\"authenticity_token\"] = authenticity_token\n",
    "\n",
    "# # Add login credentials - adjust field names if needed based on the form\n",
    "# payload[\"user[email]\"] = username\n",
    "# payload[\"user[password]\"] = password\n",
    "\n",
    "# # Set browser-like headers\n",
    "# headers = {\n",
    "#     \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.3 Safari/605.1.15\",\n",
    "#     \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "#     \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "#     \"Origin\": \"https://support.setics-sttar.com\",\n",
    "#     \"Referer\": login_url,\n",
    "# }\n",
    "\n",
    "# # Submit login\n",
    "# login_response = session.post(\n",
    "#     login_url, data=payload, headers=headers, allow_redirects=True\n",
    "# )\n",
    "# print(\n",
    "#     f\"Login status: {login_response.status_code}, URL after login: {login_response.url}\"\n",
    "# )\n",
    "\n",
    "# # Check login success by verifying cookies\n",
    "# print(f\"Cookies after login: {list(session.cookies.keys())}\")\n",
    "\n",
    "# # Try accessing the protected URL directly first to verify access\n",
    "# test_access = session.get(protected_url, headers=headers)\n",
    "# print(f\"Protected page access status: {test_access.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create discoverer with your authenticated session\n",
    "# discoverer = UrlDiscoverer(session=session, headers=headers)\n",
    "\n",
    "# # Get all URLs from the documentation site\n",
    "# docs_base_url = \"https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/en/\"\n",
    "# all_urls = discoverer.discover_urls(\n",
    "#     base_url=docs_base_url, max_depth=6, same_domain_only=True\n",
    "# )\n",
    "\n",
    "# print(f\"Discovered {len(all_urls)} URLs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_url = \"https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/en/\"\n",
    "\n",
    "# url_discovery_service.initialize(\n",
    "#     base_url=base_url, session=session, headers=headers, max_depth=5\n",
    "# )\n",
    "\n",
    "# setics_urls = url_discovery_service()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(setics_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save URLs to JSON file\n",
    "# with open(\"setics_urls.json\", \"w\") as f:\n",
    "#     json.dump(setics_urls, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setics_url_json = json.load(open(\"new_urls.json\"))\n",
    "len(setics_url_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|##########| 5/5 [00:02<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/en/topic/selection-tools-context-menu', 'title': 'Selection Tools – Context Menu - Setics Sttar Advanced Designer  |  User Manual - Version 2.3', 'description': \"Map tab - Selection tool's context menu The context menu allows you to select all the elements of the active layer in the layer control panel. It also allows you...\", 'language': 'en'}\n",
      "{'source': 'https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/en/topic/infrastructure-layers', 'title': 'Infrastructure Layers - Setics Sttar Advanced Designer  |  User Manual - Version 2.3', 'description': 'Pathways Net_Pathways Attribute Description GEOMETRY Geometry of the pathway. Type: Polyline. NETID Identification of the network. Corresponds to the ELEMENTID...', 'language': 'en'}\n",
      "{'source': 'https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/en/topic/infrastructure-table-reports', 'title': 'Infrastructure Table Reports - Setics Sttar Advanced Designer  |  User Manual - Version 2.3', 'description': 'If the routing tables reports option is checked, two table views of the infrastructure will be exported: Routing_Lines.csv Routing_Table.csv These tables are...', 'language': 'en'}\n",
      "{'source': 'https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/en/topic/equipment-database', 'title': 'Equipment Database - Setics Sttar Advanced Designer  |  User Manual - Version 2.3', 'description': 'Cabinets and Racks Cables Splice Closures Duct and Microduct Assemblies Ducts and Microduct Tubes Splitters Generic Equipment', 'language': 'en'}\n",
      "{'source': 'https://docs.setics-sttar.com/advanced-designer-user-manual/2.3/en/topic/tools-menu', 'title': 'Tools Menu - Setics Sttar Advanced Designer  |  User Manual - Version 2.3', 'description': '', 'language': 'en'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "async with SeticsWebLoaderService() as service:\n",
    "    await service.authenticate(\n",
    "        username=username,\n",
    "        password=password,\n",
    "        login_url=login_url,\n",
    "        check_url=protected_url,\n",
    "    )\n",
    "    docs = await service.load_documents(urls=setics_url_json[10:15])\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|##########| 1/1 [00:00<00:00,  9.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'https://docs.python.org/3/library/asyncio-sync.html#asyncio.Condition', 'title': 'Synchronization Primitives — Python 3.13.2 documentation', 'description': 'Source code: Lib/asyncio/locks.py asyncio synchronization primitives are designed to be similar to those of the threading module with two important caveats: asyncio primitives are not thread-safe, ...', 'language': 'en'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "python_url = \"https://docs.python.org/3/library/asyncio-sync.html#asyncio.Condition\"\n",
    "\n",
    "async with PublicWebLoaderService() as service:\n",
    "    docs = await service.load_documents_with_langchain(urls=python_url)\n",
    "\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayseregon/programming/fastapi/fastapi-ai-tools/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3554: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo_urls = setics_url_json[:5]\n",
    "# demo_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await setics_web_loader_service.authenticate(\n",
    "    username=username, password=password, login_url=login_url, check_url=protected_url\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = await setics_web_loader_service.load_documents_from_urls(\n",
    "    urls=setics_url_json[30:37]\n",
    ")\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await setics_web_loader_service.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session = setics_web_loader_service.authenticated_client\n",
    "# headers = setics_web_loader_service.request_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url_discovery_service.initialize(\n",
    "#     base_url=protected_url, session=session, headers=headers, max_depth=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_urls = url_discovery_service()\n",
    "# len(new_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url_discovery_service.to_json(\"new_urls.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_urls = setics_url_json[0:5]\n",
    "# new_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = await setics_web_loader_service.create_langchain_loader(urls=new_urls)\n",
    "# loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs = []\n",
    "# async for doc in loader.alazy_load():\n",
    "#     docs.append(doc)\n",
    "\n",
    "# len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = setics_web_loader_service.create_langchain_loader(urls=new_urls)\n",
    "# docs = loader.load()\n",
    "# len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for doc in docs:\n",
    "#     print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for doc in docs:\n",
    "#     print(doc.page_content[:300] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"setics_docs.json\", \"w\") as f:\n",
    "#     json.dump([doc.page_content for doc in docs], f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_url = \"https://docs.python.org/3/library/asyncio-sync.html#asyncio.Condition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_doc = await public_web_loader_service.load_documents(urls=python_url)\n",
    "py_doc[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(py_doc[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
